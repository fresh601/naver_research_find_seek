import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote, urlparse, parse_qs
import time

st.set_page_config(layout="wide")
st.title("ğŸ“Š ë„¤ì´ë²„ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ í¬ë¡¤ëŸ¬")

# ğŸ”¹ ì‚¬ìš©ì ì…ë ¥
item_name = st.text_input("ğŸ“ ì¢…ëª©ëª… ì…ë ¥", value="ì‚¼ì„±ì „ì")
code = st.text_input("ğŸ”‘ ì¢…ëª© ì½”ë“œ ì…ë ¥", value="005930")

# ğŸ” ê²€ìƒ‰ ë²„íŠ¼
if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘") and item_name and code:
    encoded_name = quote(item_name.encode('euc-kr'))

    headers = {
        'Referer': f'https://finance.naver.com/research/company_list.naver?keyword=&brokerCode=&writeFromDate=&writeToDate=&searchType=itemCode&itemName={encoded_name}&itemCode={code}&x=28&y=16',
        'Upgrade-Insecure-Requests': '1',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0',
        'sec-ch-ua': '"Not)A;Brand";v="8", "Chromium";v="138", "Microsoft Edge";v="138"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
    }

    # ğŸ” ë¦¬ì„œì¹˜ ëª©ë¡ ìš”ì²­
    response = requests.get(
        f'https://finance.naver.com/research/company_list.naver?keyword=&brokerCode=&writeFromDate=&writeToDate=&searchType=itemCode&itemName={encoded_name}&itemCode={code}&x=27&y=19',
        headers=headers,
    )

    html = response.text
    soup = BeautifulSoup(html, 'html.parser')

    table = soup.select_one('table.type_1')
    rows = table.select('tr') if table else []

    if not rows:
        st.warning("ë¦¬ì„œì¹˜ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        for idx, row in enumerate(rows):
            cols = row.find_all('td')
            if len(cols) >= 6:
                try:
                    report_item_name = cols[0].select_one('a.stock_item').get_text(strip=True)
                    title = cols[1].select_one('a').get_text(strip=True)
                    company = cols[2].get_text(strip=True)
                    date = cols[4].get_text(strip=True)

                    st.markdown("---")
                    st.markdown(f"### ğŸ“„ {report_item_name} | {title} | {company} | {date}")

                    # â–¶ nid ì¶”ì¶œ
                    href = cols[1].select_one('a')['href']
                    nid = parse_qs(urlparse(href).query).get('nid', [''])[0]

                    # â–¶ ìƒì„¸ í˜ì´ì§€ ìš”ì²­
                    response_detail = requests.get(
                        f'https://finance.naver.com/research/company_read.naver?nid={nid}'
                    )
                    soup_detail = BeautifulSoup(response_detail.text, 'html.parser')

                    sub_table = soup_detail.select_one('table.type_1')
                    if not sub_table:
                        st.warning("ì„¸ë¶€ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    # â–¶ í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
                    money = sub_table.select_one(".money").text.strip()
                    coment = sub_table.select_one(".coment").text.strip()

                    th_tag = sub_table.select_one('.view_sbj')
                    text_parts = [t for t in th_tag.contents if t.name is None and t.strip()]
                    sub_title = text_parts[0].strip() if text_parts else ''

                    p_tags = sub_table.select('.view_cnt > div > p')
                    sub_content1 = p_tags[0].text.strip() if len(p_tags) > 0 else ''
                    sub_content2 = '\n'.join(p.text.strip() for p in p_tags[1:]) if len(p_tags) > 1 else ''

                    # â–¶ PDF ë§í¬ ì¶”ì¶œ
                    pdf_link_tag = soup_detail.select_one('a[href$=".pdf"]')
                    pdf_link = pdf_link_tag['href'] if pdf_link_tag else None

                    # â–¶ ì¶œë ¥
                    st.markdown(f"**ğŸ¯ ëª©í‘œê°€:** {money}")
                    st.markdown(f"**ğŸ§­ íˆ¬ìì˜ê²¬:** {coment}")
                    st.markdown(f"**ğŸ”¹ ì œëª©:** {sub_title}")
                    st.markdown(f"**ğŸ”¸ ì†Œì œëª©:** {sub_content1}")
                    st.markdown("**ğŸ“‘ ë³¸ë¬¸:**")
                    st.write(sub_content2)

                    if pdf_link:
                        st.markdown("---")
                        st.markdown(f"[ğŸ“ ë¦¬í¬íŠ¸ ì›ë¬¸ ë‹¤ìš´ë¡œë“œ]({pdf_link})", unsafe_allow_html=True)

                    time.sleep(0.5)

                except Exception as e:
                    st.error(f"âš ï¸ ì˜ˆì™¸ ë°œìƒ: {e}")
                    continue
